{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6I4eycOvylvk"
   },
   "source": [
    "## Analyzing Model Performance Assignment\n",
    "In this assignment you will load a dataset and train a Logistic regression Classifier use the techniques discussed in the lesson to measure the performance. We will use the [Statlog Shuttle](http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29) dataset from UCI  to train a classifier to predict a full house.\n",
    "\n",
    "### The Dataset\n",
    "Each record contain 9 numerical attributes. The 10th column is the target column. There are two classes to predict, we will call them **positive** and **negative**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yC0ZA6dy1QV"
   },
   "source": [
    "### 1. Import necessary packages\n",
    "\n",
    "For this exercise we need\n",
    "\n",
    " - pandas\n",
    " - train_test_split\n",
    " - LogisticRegression\n",
    " - pyplot from matplotlib\n",
    " - KNeighborsClassifier\n",
    " - LogisticRegressionClassifier\n",
    " - RandomForestClassifier\n",
    " - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTA2-4TWs-Od"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.___ import confusion_matrix\n",
    "from sklearn.___ import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, classification_report\n",
    "from sklearn.___ import roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.neighbors import ___\n",
    "from sklearn.ensemble import ___\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OzR2Q1mzNsj"
   },
   "source": [
    "### 2. Load and prepare the dataset\n",
    "\n",
    "\n",
    "1.   Load the training data into a dataframe named **df_train_data** (this step is done for you).\n",
    "2.   Create binary classification problem - rename some class labels (this step done for you).\n",
    "3.   Create a dataframe of 9 features named **X**, drop column 9.\n",
    "4.   Create a data frame of labels named **y**, select only column 9.\n",
    "5.   Split the data into a training set and a test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiVjEgccA2Jf"
   },
   "outputs": [],
   "source": [
    "df_train_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/shuttle/shuttle.tst', header=None, sep=' ')\n",
    "\n",
    "df_train_data.loc[df_train_data[9] != 4, 9] = 0\n",
    "df_train_data.loc[df_train_data[9] == 4, 9] = 1\n",
    "\n",
    "X = ___\n",
    "\n",
    "y = ___\n",
    "X_train, X_test, y_train, y_test = ___(X, y)\n",
    "\n",
    "print('There are {:d} training samples and {:d} test samples'.format(X_train.shape[0], X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdUpUqvx0Xy3"
   },
   "source": [
    "### 3. Create the model\n",
    "\n",
    "\n",
    "1.   Instantiate a Logistic Regression classifier with a `lbfgs` solver.\n",
    "2.   Fit the classifier to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJZKapCoBrbZ"
   },
   "outputs": [],
   "source": [
    "lr = ____\n",
    "lr.fit(___, ___)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPOOTwC81SEJ"
   },
   "source": [
    "### 4. Calculate Accuracy\n",
    "Calculate and print the accuracy of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDb5eFMC1XwX"
   },
   "outputs": [],
   "source": [
    "lr_score = lr.score(___, ___)\n",
    "\n",
    "print('Accuracy of Logistic Regression: {:.3f}'.format(lr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aapfys9lFCmo"
   },
   "source": [
    "### 5. Dummy Classifier\n",
    "Use the dummy classifier to calculate the accuracy of a purely random chance.\n",
    "\n",
    "*Compare this result to the result ofthe logistic regression classifier above. What does this result tell you?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XC289sfmFOBX",
    "outputId": "b672da49-3965-475f-84b2-10ffd205af22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468965517241379"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = ___\n",
    "dummy.fit(___, ___)\n",
    "dummy.score(___, ___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HZWaREW2lGw"
   },
   "source": [
    "### 6. Confusion Matrix\n",
    "Print the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF_-VldG3A8I"
   },
   "outputs": [],
   "source": [
    "predictions = lr.___(X_test)\n",
    "\n",
    "confusion = confusion_matrix(___, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7PMOWWyH2lR"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9LhZoke83cHD"
   },
   "source": [
    "### 7. Plot a nicer confusion matrix (optional)\n",
    "Use the *plot_confusion_matrix* function from above to plot a nicer looking confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddNMl7kN15N3"
   },
   "outputs": [],
   "source": [
    "___(cm=___, target_names = ['Positive', 'Negative'], title = 'Confusion Matrix', normalize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39XAG5Ea4QEx"
   },
   "source": [
    "### 8. Calculate Metrics\n",
    "Print the F1, F beta, precision, recall and accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_dkF1woIgwN"
   },
   "outputs": [],
   "source": [
    "# preform calculations here\n",
    "\n",
    "print('Accuracy score: {:.2f}'.format(accuracy))\n",
    "print('Precision score: {:.2f}'.format(precision))\n",
    "print('Recall score: {:.2f}'.format(recall))\n",
    "print('F1 score: {:.2f}'.format(f1))\n",
    "print('Fbeta score favoring precision: {:.2f}'.format(fbeta_precision))\n",
    "print('FBeta score favoring recall: {:.2f}'.format(fbeta_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSM5D4XAx3tc"
   },
   "source": [
    "### 9. Print a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja4InOEUx8WO"
   },
   "outputs": [],
   "source": [
    "report = classification_report(___, ___, target_names=['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9FNqfz1yOTG"
   },
   "source": [
    "### 10. Plot ROC Curve and AUC\n",
    " Caculate AUC and plot the curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOQ1Y5WYyRta"
   },
   "outputs": [],
   "source": [
    "probs = lr.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = ___(y_test, probs)\n",
    "fig = plt.figure(figsize = (6, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Logistic Regression Model')\n",
    "plt.show()\n",
    "\n",
    "auc = ___(y_test, probs)\n",
    "print('Area under the ROC curve: {:.3f}'.format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUHIPvkeyj3M"
   },
   "source": [
    "### 11. Plot Precision-Recall Curve\n",
    "Plot the precision-recall curve for the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIZDuZAmyoOg"
   },
   "outputs": [],
   "source": [
    "pres, rec, thresholds = ___(y_test, predictions)\n",
    "fig = plt.figure(figsize = (6, 6))\n",
    "plt.plot(rec, pres)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvMrufbgVkNr"
   },
   "source": [
    "Find the best value for C in the Logistic Regression Classifier for avoiding overfitting. Plot the training and testing accuracy over a range of C values from 0.05 to 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKexe4OjzpFP"
   },
   "outputs": [],
   "source": [
    "c_vals = np.arange(0.05, 1.5, 0.05)\n",
    "test_accuracy = []\n",
    "train_accuracy = []\n",
    "\n",
    "for c in c_vals:\n",
    "  lr = ___\n",
    "  lr.fit(___, ___)\n",
    "  test_accuracy.append(lr.score(X_test, y_test))\n",
    "  train_accuracy.append(lr.score(X_train, y_train))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(c_vals, test_accuracy, '-g', label='Test Accuracy')\n",
    "ax1.plot(c_vals, train_accuracy, '-b', label='Train Accuracy')\n",
    "ax1.set(xlabel='C', ylabel='Accuracy')\n",
    "ax1.set_title('Effect of C on Accuracy')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U6_cL8lszJr6"
   },
   "source": [
    "### 12. Cross Validation\n",
    "Perform 5-fold cross validation for a Logistic Regression Classifier. Print the 5 accuracy scores and the mean validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K0-tPtUzPEJ"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "cv_scores = ___(clf, ___, y_train, cv = ___)\n",
    "\n",
    "print('Accuracy scores for the 5 folds: ', cv_scores)\n",
    "print('Mean cross validation score: {:.3f}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgSUjo0B13lT"
   },
   "source": [
    "### 13. Is this really linear?\n",
    "Our linear classifier is not giving us accuracy better than the dummy classifier. Suppose that the data was not linearly separable? Instantiate and train a KNN model with k = 7. How does the accuracy of the KNN model compare to the Logistic Regression from above? What does that tell you about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19AtIXgW0Kfk"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7V3vAloG2dU-"
   },
   "source": [
    "### 14. Random Forest\n",
    "Next, instantiate and fit a RandomForestClassifier and calculate the accuracy of that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YLLplge2fxT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Analyzing Model Performance Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
