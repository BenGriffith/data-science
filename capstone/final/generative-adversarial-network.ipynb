{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import keras\n",
    "import warnings\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "# Display preference\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(driver, timeout):\n",
    "    \n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "    \n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait\n",
    "        time.sleep(timeout)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            \n",
    "            break\n",
    "        \n",
    "        last_height = new_height   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options\n",
    "options = Options()\n",
    "options.set_preference('permissions.default.image', 2)\n",
    "options.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', False)\n",
    "\n",
    "def all_links(url, action, gender=0):\n",
    "    \n",
    "    # Setup driver\n",
    "    driver = webdriver.Firefox(options=options, executable_path='D:/Users/bengriffith/Desktop/geckodriver.exe')\n",
    "\n",
    "    # Wait before throwing an exception\n",
    "    driver.implicitly_wait(20)\n",
    "\n",
    "    # Open the page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Start scrolling\n",
    "    scroll(driver, 10)\n",
    "    \n",
    "    # Beautiful Soup parses page_source\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    # Close the driver\n",
    "    driver.close()\n",
    "\n",
    "    if action == 1:\n",
    "    \n",
    "        # Empty dictionary to store m from page source\n",
    "        get_m = {}\n",
    "    \n",
    "        # Counter for get_m dictionary\n",
    "        get_m_counter = 0\n",
    "\n",
    "        # Looping through all the a elements in the page source\n",
    "        for link in soup.find_all('a', {'class': 'iusc'}):\n",
    "    \n",
    "            # Add values to dictionary\n",
    "            get_m[get_m_counter] = link.get('m')\n",
    "        \n",
    "            # Increment counter\n",
    "            get_m_counter += 1\n",
    "        \n",
    "        # Convert from string to dictionary\n",
    "        for key, value in get_m.items():\n",
    "            get_m[key] = json.loads(value)\n",
    "        \n",
    "        # Empty list to store image links\n",
    "        links = []\n",
    "    \n",
    "        # Loop through get_m dictionary and add image links to links list\n",
    "        for value in get_m.values():\n",
    "            links.append([value['murl'], gender])\n",
    "        \n",
    "        return links\n",
    "    else:\n",
    "        return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of names to search\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular names url\n",
    "name_url = 'https://www.ssa.gov/oact/babynames/decades/century.html'\n",
    "\n",
    "# Beautiful Soup object\n",
    "soup_name = all_links(name_url, 0)\n",
    "\n",
    "# Get td tag\n",
    "td_tag = soup_name.select('.t-stripe > tbody > tr > td')\n",
    "\n",
    "# Add name to search names\n",
    "names += [name.get_text().lower() for name in td_tag if name.get_text().isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for male names\n",
    "male_names = []\n",
    "\n",
    "# List for female names\n",
    "female_names = []\n",
    "\n",
    "for index, name in enumerate(names, 0):\n",
    "    if index % 2 == 0:\n",
    "        male_names.append([name, 0])\n",
    "    else:\n",
    "        female_names.append([name, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image links for each name\n",
    "def get_links(names):\n",
    "    \n",
    "    image_links_name = []\n",
    "    \n",
    "    for index in range(len(names)):\n",
    "        \n",
    "        # Update url\n",
    "        url = 'https://www.bing.com/images/search?q=' + names[index][0] + '&qs=n&form=QBIR&qft=%20filterui%3Alicense-L2_L3_L4_L5_L6_L7%20filterui%3Aface-face&sp=-1&pq=' + names[index][0] + '&sc=8-9&sk=&cvid=8C2D8EC9A35A4948980A61669549C180'\n",
    "    \n",
    "        # Add image links\n",
    "        image_links_name += all_links(url, 1, names[index][1])\n",
    "        \n",
    "    return image_links_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for image links\n",
    "image_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add male name image links\n",
    "image_links += get_links(male_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add female name image links\n",
    "image_links += get_links(female_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shuffle image links list\n",
    "random.shuffle(image_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 8 files removed due to a Request / Response Exception\n"
     ]
    }
   ],
   "source": [
    "# Header to accompany get request\n",
    "headers = {'user-agent': 'scraper - school project (bengriffith@outlook.com)'}\n",
    "\n",
    "# Counter to be used in image file name\n",
    "image_counter = 0\n",
    "\n",
    "# Counter for exceptions occurred\n",
    "exception_counter = 0\n",
    "\n",
    "# Write images to disk\n",
    "for image_link in image_links[:5000]:\n",
    "    with open('images/face_' + str(image_counter) + '_' + str(image_link[1]) + '.png', 'wb') as f:\n",
    "        try:\n",
    "            response = requests.get(image_link[0], headers=headers)\n",
    "            \n",
    "            if response.ok:\n",
    "                f.write(response.content)\n",
    "        except:\n",
    "            exception_counter += 1\n",
    "            continue\n",
    "    image_counter += 1\n",
    "    \n",
    "print('There were {} files removed due to a Request / Response Exception'.format(exception_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_directory = 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 56 files removed due to AttributeError\n"
     ]
    }
   ],
   "source": [
    "files_removed = 0\n",
    "\n",
    "for filename in os.listdir(images_directory)[1:]:\n",
    "    try:\n",
    "        image = cv2.imread(images_directory + filename)\n",
    "        (h, w) = image.shape[:2]\n",
    "    except AttributeError:\n",
    "        files_removed += 1\n",
    "        os.remove(images_directory + filename)\n",
    "        \n",
    "print('There were {} files removed due to AttributeError'.format(files_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt = 'supporting/deploy.prototxt'\n",
    "model = 'supporting/res10_300x300_ssd_iter_140000.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store detected face\n",
    "data = []\n",
    "\n",
    "# List to store labels\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(images_directory)[1:]:\n",
    "    image_path = images_directory + filename\n",
    "    \n",
    "    \n",
    "    net = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (10, 10)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    for i in range(detections.shape[2]):\n",
    "    \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "        if confidence > 0.3:\n",
    "        \n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype('int')\n",
    "        \n",
    "            #text = '{:.2f}%'.format(confidence * 100)\n",
    "            #y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            #cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "            #cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "        \n",
    "            face = image[startY:endY, startX:endX]\n",
    "            face = cv2.resize(face, (32, 32)).flatten()\n",
    "            data.append(face)\n",
    "            labels.append(float(filename[filename.find('.') - 1]))\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy arrays\n",
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3811,)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2858, 3072)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1940, 1871], dtype=int64)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2858 samples, validate on 953 samples\n",
      "Epoch 1/20\n",
      "2858/2858 [==============================] - 22s 8ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 2/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 3/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 4/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 5/20\n",
      "2858/2858 [==============================] - 23s 8ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 6/20\n",
      "2858/2858 [==============================] - 29s 10ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 7/20\n",
      "2858/2858 [==============================] - 25s 9ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 8/20\n",
      "2858/2858 [==============================] - 27s 9ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 9/20\n",
      "2858/2858 [==============================] - 24s 9ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 10/20\n",
      "2858/2858 [==============================] - 23s 8ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 11/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 12/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 13/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 14/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 15/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 16/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 17/20\n",
      "2858/2858 [==============================] - 22s 8ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 18/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 19/20\n",
      "2858/2858 [==============================] - 22s 8ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Epoch 20/20\n",
      "2858/2858 [==============================] - 21s 7ms/step - loss: 8.2055 - accuracy: 0.4853 - val_loss: 7.8457 - val_accuracy: 0.5079\n",
      "Test loss: 7.845728092153575\n",
      "Test accuracy: 0.5078698992729187\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to recognize whether male or female\n",
    "\n",
    "# If female then choose female GAN\n",
    "\n",
    "# If male then choose male GAN\n",
    "\n",
    "# Will need to create / train female and male GANs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
